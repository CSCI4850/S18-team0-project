{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team 0 Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Charles Johnson, Miles Baer, Nathaniel Boyer, Rex Cope, Robert Smith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Based Feature Extraction Concerning Amazon Reviewers' Authorship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Amazon has many products ranging from food to electronics and much more. Given the huge number of products supplied by amazon, there needs to be a way to rate these products to give customers a sense of which are good or bad for example. Our goal is to take these reviews of various products and try to determine authorship. We need to determine the features that will help us do this. These could range from word frequency to paragraph length and so on. Using a convolutional neural network, we hope to have it find the important features to use when looking at authorship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The technologies we will be using consist of two types of neural networks. The major component of this project will be the use of a convolutional neural network. Convolutional networks are equipped at finding relevant pattern or feature sets that humans are usually not capable of producing, at least not in a timely manner. The idea is to use it to extract what it deems as important features to use for classification in a traditional neural network. The traditional net will let us know if the features that were extracted are useful in accurately guessing the author. The concern is how to encode the textual data in such a way that the convolutional network finds the best or most important features for the classification of the Amazon reviewers’ authorship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;There a several different ways of encoding the data to suit a convolutional neural network. We could try encoding a vector of single characters, but this would take too long to train considering the number of all possible patterns for each set. Another way would be to make a vector of words. To go even further, you could encode sentences and even paragraphs in the same manner. Before actually encoding them, there are some minor things to consider. Should any characters be ignored? Sentences end in punctuation but is it necessary for good feature extraction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The next concern is the window size of the vectors being used. For example, in the vector of words, how many should be examined at once? Determining window size is crucial to helping the net learn and be able to extract relevant. Another way to say this is to determine our filtering size. How many words or sentences should be pooled together to give us appropriate class labels? After choosing the appropriate sizes and number of filters, random initialization of each filter would most likely produce the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;There is a data set of around twenty-two gigabytes containing Amazon reviews. This should be sufficiently large enough to get some detailed results. It is all in a well-managed JSON format, so it should be simple to parse through. To gain access you must contact Julian McAuley, but that shouldn't be a big problem. There are many smaller datasets to play around with until he sends it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;What we will be trying to examine is which one of the above-mentioned encoding methods results in the best feature extraction and learning of the convolutional neural network. Each encoding will be used to train a convolutional neural network. Afterwards, we will use the features extracted in a conventional neural net to try and classify specific reviewers on Amazon. The resulting encoding that produces the best feature set for classification should give a higher accuracy rating when classified, in turn, determining which encoding works best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Liang, H., Sun, X., Sun, Y. and Gao, Y. (2017). Text feature extraction based on deep learning: a review. EURASIP Journal on Wireless Communications and Networking, [online] 2017(1). Available at: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5732309/ [Accessed 28 Feb. 2018].\n",
    "\n",
    "Research Gate. (2018). How do we choose the filters for the convolutional layer of a Convolution Neural Network (CNN)?. [online] Available at: https://www.researchgate.net/post/How_do_we_choose_the_filters_for_the_convolutional_layer_of_a_Convolution_Neural_Network_CNN [Accessed 1 Mar. 2018].\n",
    "\n",
    "Towards Data Science. (2018). Understanding how Convolutional Neural Network (CNN) perform text classification with word…. [online] Available at: https://towardsdatascience.com/understanding-how-convolutional-neural-network-cnn-perform-text-classification-with-word-d2ee64b9dd0b [Accessed 1 Mar. 2018]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
